{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-driving car Nanodegree - Term 1\n",
    "\n",
    "## Project 2: **Behavior Cloning** \n",
    "***\n",
    "In this project, we will use deep neural networks and convolutional neural networks to clone driving behavior. The model will output a steering angle to an autonomous vehicle.\n",
    "\n",
    "Author : [Tran Ly Vu](https://github.com/tranlyvu)\n",
    "\n",
    "- [Github repo](https://github.com/tranlyvu/autonomous-vehicle-projects/tree/master/Behavioral%20Cloning)\n",
    "- [Notebook](http://nbviewer.jupyter.org/gist/tranlyvu/df59fa9ea4a18f373947ca5c04bec801)\n",
    "- [Python code](https://github.com/tranlyvu/autonomous-vehicle-projects/tree/master/Finding%20Lane%20Lines/src/finding_lane_lines.py)\n",
    "\n",
    "---\n",
    "### Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Convolution2D, Cropping2D, Lambda, Dropout\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "# Visualizations will be shown in the notebook.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Read data'''\n",
    "image_path = '../../../data'\n",
    "driving_log_path = '../../../data/driving_log.csv'\n",
    "\n",
    "rows = []\n",
    "with open(driving_log_path) as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for row in reader:\n",
    "        rows.append(row)\n",
    "\n",
    "def append_data(col, images, measurement, steering_measurements):\n",
    "    current_path = image_path + '/' + col.strip()\n",
    "    image = cv2.imread(current_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    images.append(image)\n",
    "    steering_measurements.append(measurement)\n",
    "    image_flipped = np.fliplr(image)\n",
    "    images.append(image_flipped)\n",
    "    measurement_flipped = measurement * (-1)\n",
    "    steering_measurements.append(measurement)\n",
    "          \n",
    "\n",
    "def images_and_measurements(sample):\n",
    "    images = []\n",
    "    steering_measurements = []\n",
    "    for line in sample[0:]:\n",
    "        measurement = float(line[3])\n",
    "        #center\n",
    "        col_center = line[0]\n",
    "        append_data(col_center, images, measurement, steering_measurements)\n",
    "        #left\n",
    "        col_left = line[1]\n",
    "        append_data(col_left, images, measurement + 0.2, steering_measurements)\n",
    "        #right\n",
    "        col_right = line[2]\n",
    "        append_data(col_right, images, measurement - 0.2, steering_measurements)\n",
    "    return images, steering_measurements\n",
    "\n",
    "def generator(samples, batch_size = 32):\n",
    "    num_samples = len(samples)\n",
    "    while 1:\n",
    "        sklearn.utils.shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset + batch_size]           \n",
    "            images = []\n",
    "            measurements = []\n",
    "            for image, measurement in batch_samples:\n",
    "                images.append(image)   \n",
    "                measurements.append(measurement)\n",
    "            # trim image to only see section with road\n",
    "            x_train = np.array(images)\n",
    "            y_train = np.array(measurements)\n",
    "            yield sklearn.utils.shuffle(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First attempt\n",
    "In [my first attempt](https://github.com/tranlyvu/autonomous-vehicle-projects/blob/master/Behavioral%20Cloning/src/first_attempt.py), I used 9-layers network from [end to end learning for self-driving cars](https://arxiv.org/pdf/1604.07316.pdf) by NVIDIA \n",
    "\n",
    "1. Pre-processing pipeline\n",
    "    - Data augmentation: Flipping images\n",
    "    - Normalization\n",
    "    - Mean centering\n",
    "2. NVIDIA original model\n",
    "    \n",
    "|Layer   |type    |output filter/neurons|\n",
    "|--------|--------|--------|\n",
    "|1       |conv    |24      |\n",
    "|2       |conv    |36      |\n",
    "|3       |conv    |48      |\n",
    "|4       |conv    |64      |\n",
    "|5       |conv    |64      |\n",
    "|6       |flattern|1164    |\n",
    "|7       |relu    |100     |\n",
    "|8       |relu    |50      |\n",
    "|9       |relu    |10      |\n",
    "|10      |relu    |1       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Second attempt\n",
    "\n",
    "However, I detected overfitting in my first attempt, and hence i tried to improved the mode in second model by using regulation, i.e dropout\n",
    "\n",
    "1. Pre-processing pipeline\n",
    "    - Data augmentation: Flipping images\n",
    "    - Normalization\n",
    "    - Mean centering\n",
    "2. Modified NVIDIA model\n",
    "    \n",
    "|Layer   |type    |output filter/neurons|\n",
    "|--------|--------|--------|\n",
    "|1       |conv    |24      |\n",
    "|        |dropout |        |\n",
    "|2       |conv    |36      |\n",
    "|        |dropout |        |\n",
    "|3       |conv    |48      |\n",
    "|        |dropout |        |\n",
    "|4       |conv    |64      |\n",
    "|5       |conv    |64      |\n",
    "|6       |flattern|1164    |\n",
    "|7       |relu    |100     |\n",
    "|8       |relu    |50      |\n",
    "|9       |relu    |10      |\n",
    "|10      |relu    |1       |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#The cameras in the simulator capture 160 pixel by 320 pixel images., after cropping, it is 66x200\n",
    "model.add(Cropping2D(cropping = ((74,20), (60,60)),input_shape=(160, 320, 3)))\n",
    "\n",
    "model.add(Lambda(lambda x: x / 255.0 - 0.5, input_shape=(66, 200, 3)))\n",
    "model.add(Convolution2D(24, 5, 5, subsample=(2,2), activation='relu'))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Convolution2D(36, 5, 5, subsample=(2,2), activation='relu'))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Convolution2D(48, 5, 5, subsample=(2,2), activation='relu'))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu'))  \n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(50))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))\n",
    "'''Training: using MSE for regression'''\n",
    "model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Print total number of data , including augmentation\n",
    "X_total, y_total = images_and_measurements(rows[1:])\n",
    "print(\"Number of image is: {}\", len(X_total))\n",
    "print(\"Number of measurement is: {}\", len(y_total))\n",
    "\n",
    "print('Training model')            \n",
    "samples = list(zip(X_total, y_total))          \n",
    "train_samples, validation_samples = train_test_split(samples, test_size = 0.2)\n",
    "train_generator = generator(train_samples, batch_size = 32)\n",
    "validation_generator = generator(validation_samples, batch_size = 32)\n",
    "\n",
    "\n",
    "history_object = model.fit_generator(train_generator,\n",
    "                                    samples_per_epoch = len(train_samples),\n",
    "                                    validation_data = validation_generator,\n",
    "                                    nb_val_samples = len(validation_samples),\n",
    "                                    nb_epoch = 25, \n",
    "                                    verbose=1)\n",
    "print('Endding training, starting to save model')\n",
    "model.save('../model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(history_object.history.keys())\n",
    "###plot the training and validation loss for each epoch\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
