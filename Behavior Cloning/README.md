# Behavior Cloning 

Overview
---

In this project, we will use deep neural networks and convolutional neural networks to clone driving behavior. The model will output a steering angle to an autonomous vehicle.

The goals / steps of this project are the following:
* Use the [simulator](https://github.com/udacity/self-driving-car-sim) to collect data of good driving behavior 
* Design, train and validate a model that predicts a steering angle from image data
* Use the model to drive the vehicle autonomously around the first track in the simulator. The vehicle should remain on the road for an entire loop around the track.
* Summarize the results with a written report

Here are the [notebook](http://nbviewer.jupyter.org/gist/tranlyvu/671c4e258dcc5535f27e458e346c64e9) and [source code](https://github.com/tranlyvu/autonomous-vehicle-projects/blob/master/Behavioral%20Cloning/src/model.py) of the project.

The project video is [here](https://youtu.be/TYh4y5VDFkE).

Project Writeup
---

### Files Submitted 

My project includes the following files:

```
- src/model.py containing the script to create and train the model
- drive.py for driving the car in autonomous mode
- model.h5 containing a trained convolution neural network
- notebook containing notebook
- run1.mp4 containing sample video of driving the car in autonomous mode using trained model 
```

Using the Udacity provided [simulator](https://github.com/udacity/self-driving-car-sim) and my drive.py file, I was able to test my model by driving autonomously around the track by executing:

```
python drive.py model.h5
```

Video of driving the car was generated by executing:

```
python drive.py model.h5 run1
python video.py run1 --fps 48
```


### Dataset

I used training dataset provided by Udacity. I use all 3 positions of camera with correction of 0.25 , i.e addition of 0.25 to steering angle for left-positioned camera and substraction of 0.25 for right-positioned camera.

I could have self-produced ore data but due to time constraint, I only used Udacity dataset

Moreover, after unable to complete a whole lap, I follow advice from forum and decided to randomly choose camera to select from

The dataset is split into 20% of test set. Also, the training set is shuffled before training

### Data Preprocessing

My pre-processing pipeline including:

```
- Data augmentation: Fliping the image horizontal randomly 
- Cropping the image to 66x200 to fit NVIDIA model
- Normalization and Mean centering
```

Again, Flipping the image randomly was recommended by forum mentor.


### Model Architecture and Training Strategy

In my [first attempt](https://github.com/tranlyvu/autonomous-vehicle-projects/blob/master/Behavioral%20Cloning/src/first_attempt.py), I used 9-layers network from end to end learning for self-driving cars by NVIDIA as recommended by Udacity

    
|Layer   |type    |output filter/neurons|
|--------|--------|--------|
|1       |conv    |24      |
|2       |conv    |36      |
|3       |conv    |48      |
|4       |conv    |64      |
|5       |conv    |64      |
|6       |flattern|1164    |
|7       |relu    |100     |
|8       |relu    |50      |
|9       |relu    |10      |
|10      |relu    |1       |


However, I detected overfitting in my first attempt as they training and validation loss did not converge, hence I tried to combat overfitting in the second model by applying regulation, i.e dropout

|Layer   |type    |output filter/neurons|
|--------|--------|--------|
|1       |conv    |24      |
|        |dropout |        |
|2       |conv    |36      |
|        |dropout |        |
|3       |conv    |48      |
|        |dropout |        |
|4       |conv    |64      |
|5       |conv    |64      |
|6       |flattern|1164    |
|7       |relu    |100     |
|8       |relu    |50      |
|9       |relu    |10      |
|10      |relu    |1       |

For every time of training and parameter tunning, the model was tested by running it through the simulator and ensuring that the vehicle could stay on the track.

At epoch of 10, the training and validation loss both went down fast and I think they would converge if I'd have increased number of epoch (graph is plotted in the [notebook](http://nbviewer.jupyter.org/gist/tranlyvu/671c4e258dcc5535f27e458e346c64e9). However, for this kind of regression problem, both trainning loss and accuracy do not seem to be useful, it is more important to test it on the [simulator](https://github.com/udacity/self-driving-car-sim) provided by Udacity. Therefore, I simply tune number of epoch until the vehicle run well on the track.

Final Model parameters:

```
- Optimizer: Adam optimizer, so the learning rate was not tuned manually 
- Epoch: 5
- Batch size: 32
```

The project video is [here](https://youtu.be/TYh4y5VDFkE).
